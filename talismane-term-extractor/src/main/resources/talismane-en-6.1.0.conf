# Configuration the Penn-to-Dependency corpus, automatically converted from
# constituent trees to dependencies as per Richard Johansson and Pierre Nugues,
# Extended Constituent-to-dependency Conversion for English, Proceedings of
# NODALIDA 2007, May 25-26, 2007, Tartu, Estonia,
# http://nlp.cs.lth.se/software/treebank_converter/">http://nlp.cs.lth.se/software/treebank_converter/
#
# Configuration author: Assaf Urieli

englishLanguagePack="zip://languagePacks/englishLanguagePack-6.1.0.zip!"

input-pattern="%INDEX%\t%TOKEN%\t%LEMMA%\t%POSTAG%\t%CATEGORY%\t%MORPHOLOGY%\t%NON_PROJ_GOVERNOR%\t%NON_PROJ_LABEL%\t%GOVERNOR%\t%LABEL%"

corpus-rules = [
  {
    criteria = { TOKEN = "(``|'')" }
    actions = {
      TOKEN = "\""
    }
  },
  {
    criteria = { POSTAG = "(``|'')" }
    actions = {
      POSTAG = "P"
      TOKEN = "\""
    }
  },
  {
    criteria = { POSTAG = "[,:.()]" }
    actions = { POSTAG = "P" }
  },
  {
    criteria = { POSTAG = "#" }
    actions = {
      POSTAG = "NNS"
      TOKEN = "£"
    }
  },
  {
    criteria = { POSTAG = "[$£¥]" }
    actions = { POSTAG = "NNS" }
  },
  {
    criteria = { POSTAG = "%" }
    actions = { POSTAG = "NN" }
  }
]

talismane {
  core {
    en = ${talismane.core.generic} {
      locale = en
    
      lexicons = [
        ${englishLanguagePack}"lexicons_en.zip"
      ]
      
      annotators {
        text-annotators = [
          ${englishLanguagePack}"text_marker_filters.txt"
        ]
        
        sentence-annotators = [
          ${englishLanguagePack}"token_filters.txt"
        ]
      }
      
      sentence-detector {
        model = ${englishLanguagePack}"sentence_penn_all_maxent_cut5.zip"

        train {
          corpus-reader = com.joliciel.talismane.tokeniser.TokenRegexBasedCorpusReader
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features = "englishLanguagePacks/english/features/sentenceDetector_en_baseline.txt"
        }
      }
      
      tokeniser {
        type = pattern

        filters = [
          com.joliciel.talismane.tokeniser.filters.QuoteNormaliser
          com.joliciel.talismane.tokeniser.filters.LowercaseKnownFirstWordFilter
          com.joliciel.talismane.tokeniser.filters.UppercaseSeriesFilter
        ]

        model = ${englishLanguagePack}"tokeniser_penn_all_maxent_cut5.zip"
        
        train {
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features="englishLanguagePacks/english/features/tokeniser_en_baseline.txt"
          patterns="englishLanguagePacks/english/features/tokeniserPatterns_en.txt"
        }
      }
      
      pos-tagger {
        pos-tag-set = ${englishLanguagePack}"pennTagset.txt"
        
        pos-tag-map = {
          Dela = ${englishLanguagePack}"dela-en_posTagMap.txt"
        }
        
        rules = [
          ${englishLanguagePack}"posTaggerConstraints_en.txt"
        ]

        model = ${englishLanguagePack}"posTagger_penn_all_maxent_cut5.zip"

        train {
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features="englishLanguagePacks/english/features/posTagger_en_baseline.txt"
        }
      }
      
      parser {      
        dependency-labels = ${englishLanguagePack}"pennDependencyLabels.txt"
        
        model = ${englishLanguagePack}"parser_penn_all_maxent_cut10.zip"

        train {
          input-pattern = ${input-pattern}
          corpus-rules = ${corpus-rules}

          features="englishLanguagePacks/english/features/parser_en_baseline.txt" 
        }
        
      }
    }
  }
}
